================================================================================
                    TASTE KARACHI - FREQUENTLY ASKED QUESTIONS (FAQ)
================================================================================

Last Updated: October 2025
Version: 1.0


TABLE OF CONTENTS
-----------------
1. General Setup
2. Windows Setup
3. Mac/Linux Setup
4. Common Build Errors
5. Docker Issues
6. Model & Data Issues
7. API Issues
8. Development Environment Issues
9. MLflow Issues
10. Troubleshooting Tips


================================================================================
1. GENERAL SETUP
================================================================================

Q: What are the prerequisites for running this project?
A: You need:
   - Python 3.10 or 3.11 (Python 3.10 recommended for Docker compatibility)
   - Docker Desktop (for containerized deployment)
   - Git (for version control)
   - At least 2GB of free disk space
   - Internet connection for downloading dependencies

Q: What is the recommended way to run this project?
A: Use Docker Compose for the easiest setup:

   docker-compose up --build

   This will start both the FastAPI backend (port 8000) and Streamlit frontend
   (port 8501) automatically.

Q: Where can I find the trained model?
A: The trained model is located in the models/ directory. The main model file is:
   - models/model.pkl (699KB Gradient Boosting model)
   - models/MLmodel (MLflow metadata)

   Note: The models/ directory is gitignored, so you need to train the model
   first by running notebooks/train.ipynb

Q: How do I train the model from scratch?
A: Follow these steps:
   1. Ensure you have the data in data/restaurants.csv
   2. Run notebooks/clean.ipynb to generate train_set.csv and holdout_test_set.csv
   3. Run notebooks/train.ipynb to train the model
   4. The best model will be saved to models/ directory


================================================================================
2. WINDOWS SETUP
================================================================================

Q: How do I set up Python virtual environment on Windows?
A: Using PowerShell or Command Prompt:

   # Create virtual environment
   python -m venv venv

   # Activate (PowerShell)
   .\venv\Scripts\Activate.ps1

   # Activate (Command Prompt)
   .\venv\Scripts\activate.bat

   # Install dependencies
   pip install --upgrade pip
   pip install -r requirements.txt

Q: I get "Execution Policy" error when activating virtual environment on Windows
A: Run PowerShell as Administrator and execute:

   Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

   Then try activating the virtual environment again.

Q: Docker Desktop on Windows won't start or shows WSL error
A: Solutions:
   1. Enable WSL 2:
      - Open PowerShell as Administrator
      - Run: wsl --install
      - Restart your computer

   2. Enable Virtualization in BIOS:
      - Restart computer and enter BIOS (usually F2, F10, or Del)
      - Enable Intel VT-x or AMD-V
      - Save and exit

   3. Update Docker Desktop to latest version

   4. Ensure WSL 2 is default:
      wsl --set-default-version 2

Q: How do I check if ports 8000 or 8501 are already in use on Windows?
A: Run in Command Prompt:

   netstat -ano | findstr :8000
   netstat -ano | findstr :8501

   To kill a process using a port:
   taskkill /PID <process_id> /F

Q: Python or pip is not recognized on Windows
A: Add Python to PATH:
   1. Search "Environment Variables" in Start Menu
   2. Click "Environment Variables"
   3. Under System Variables, find "Path" and click Edit
   4. Add Python installation directory (e.g., C:\Python310)
   5. Add Scripts directory (e.g., C:\Python310\Scripts)
   6. Click OK and restart Command Prompt


================================================================================
3. MAC/LINUX SETUP
================================================================================

Q: How do I set up Python virtual environment on Mac/Linux?
A: Using Terminal:

   # Create virtual environment
   python3 -m venv venv

   # Activate
   source venv/bin/activate

   # Install dependencies
   pip install --upgrade pip
   pip install -r requirements.txt

Q: I get permission denied when installing packages on Mac/Linux
A: Solutions:
   1. Use virtual environment (recommended):
      python3 -m venv venv
      source venv/bin/activate
      pip install -r requirements.txt

   2. Or use --user flag:
      pip install --user -r requirements.txt

   DO NOT use sudo pip install (can break system Python)

Q: Docker Desktop on Mac shows "Docker daemon not running" error
A: Solutions:
   1. Open Docker Desktop application
   2. Wait for Docker to fully start (whale icon in menu bar)
   3. If stuck, restart Docker Desktop
   4. Check Activity Monitor for conflicting processes
   5. Try: docker info to verify connection

Q: How do I check if ports are in use on Mac/Linux?
A: Run in Terminal:

   # Check port 8000
   lsof -i :8000

   # Check port 8501
   lsof -i :8501

   To kill a process:
   kill -9 <PID>

Q: Mac M1/M2 (Apple Silicon) compatibility issues
A: The Dockerfile uses --platform=$BUILDPLATFORM for multi-architecture support.

   If you encounter issues:
   1. Ensure Docker Desktop is latest version
   2. Enable Rosetta emulation in Docker Desktop settings
   3. Build specifically for ARM64:
      docker build --platform linux/arm64 -t taste-karachi .

Q: "command not found: python" on Mac/Linux
A: Mac/Linux often use python3 instead of python:

   # Check Python version
   python3 --version

   # Create alias (add to ~/.bashrc or ~/.zshrc)
   alias python=python3
   alias pip=pip3


================================================================================
4. COMMON BUILD ERRORS
================================================================================

Q: ERROR: Could not find a version that satisfies the requirement <package>
A: Solutions:
   1. Upgrade pip:
      pip install --upgrade pip

   2. Check Python version compatibility (requires 3.10 or 3.11):
      python --version

   3. Try installing package individually to see specific error:
      pip install <package_name>==<version>

   4. Check for typos in requirements.txt

Q: ERROR: No matching distribution found for packaging<24.0
A: This constraint may conflict with other packages. Try:

   pip install --upgrade pip setuptools wheel
   pip install packaging==23.2
   pip install -r requirements.txt

Q: ModuleNotFoundError: No module named 'sklearn'
A: The package name is scikit-learn, not sklearn:

   pip install scikit-learn==1.3.2

   In code, it's imported as:
   import sklearn  # This is correct

Q: Error building Docker image: "failed to solve with frontend dockerfile.v0"
A: Solutions:
   1. Update Docker Desktop to latest version
   2. Clear Docker build cache:
      docker builder prune -a
   3. Rebuild without cache:
      docker-compose build --no-cache
   4. Check Dockerfile syntax for errors

Q: NumPy/SciPy build errors on Windows
A: Install Microsoft C++ Build Tools:
   1. Download from: https://visualstudio.microsoft.com/visual-cpp-build-tools/
   2. Install "Desktop development with C++"
   3. Restart computer
   4. Try pip install again

   OR use pre-built wheels:
   pip install --only-binary :all: numpy scipy

Q: Pydantic validation errors or version conflicts
A: The project supports both Pydantic v1 and v2. Code in src/api.py handles both:

   # Check your Pydantic version
   pip show pydantic

   # If issues persist, use specific version
   pip install pydantic==2.5.2


================================================================================
5. DOCKER ISSUES
================================================================================

Q: Docker build fails with "failed to compute cache key"
A: Solutions:
   1. Ensure all files referenced in Dockerfile exist
   2. Check .dockerignore isn't excluding required files
   3. Build without cache:
      docker build --no-cache -t taste-karachi .

Q: Container starts but API returns 503 Service Unavailable
A: The model isn't loaded. Check:
   1. models/ directory exists and contains model.pkl
   2. Check container logs:
      docker logs taste-karachi-api
   3. Ensure models/ is mounted in docker-compose.yml (it is by default)
   4. Train the model first using notebooks/train.ipynb

Q: "ERROR: [Errno 13] Permission denied" in Docker container
A: On Linux, fix file permissions:

   sudo chown -R $USER:$USER ./models
   sudo chown -R $USER:$USER ./data

Q: Docker Compose "network taste-karachi-network not found"
A: Create network or let Docker Compose create it automatically:

   # Remove all containers and networks
   docker-compose down

   # Recreate everything
   docker-compose up --build

Q: Container exits immediately with code 137
A: This is an Out of Memory (OOM) error. Solutions:
   1. Increase Docker Desktop memory allocation:
      - Settings > Resources > Memory (allocate at least 4GB)
   2. Close other applications
   3. Check model file size (should be ~699KB)

Q: How do I access container shell for debugging?
A: For running container:

   docker exec -it taste-karachi-api bash

   For one-off debugging:
   docker run -it --rm taste-karachi bash


================================================================================
6. MODEL & DATA ISSUES
================================================================================

Q: FileNotFoundError: data/restaurants.csv not found
A: The data/ directory is gitignored. You need to:
   1. Obtain the restaurants.csv dataset
   2. Create data/ directory: mkdir data
   3. Place restaurants.csv in data/
   4. Run notebooks/clean.ipynb to process data

Q: Model prediction returns unexpected values
A: Check:
   1. Input features match training schema (28 features total)
   2. Categorical values match training data:
      - area: Must be one of 67 valid Karachi areas
      - price_level: PRICE_LEVEL_INEXPENSIVE/MODERATE/EXPENSIVE/VERY_EXPENSIVE
      - category: Restaurant types (Pakistani, Fast Food, Cafe, etc.)
   3. Latitude/Longitude are in valid Karachi range (~24.8-25.0, ~66.9-67.2)

Q: MLflow model loading fails
A: Solutions:
   1. Ensure MLflow version matches (2.9.0):
      pip install mlflow==2.9.0

   2. Check model files exist in models/:
      - model.pkl
      - MLmodel
      - conda.yaml
      - python_env.yaml

   3. Verify Python version compatibility (3.10 or 3.11)

   4. Try loading manually to see detailed error:
      import mlflow
      model = mlflow.pyfunc.load_model("./models")

Q: High Mean Absolute Error (MAE) on predictions
A: Expected MAE is ~0.178 (best model). If higher:
   1. Ensure you're using the best_gradient_boosting_model
   2. Check if using correct train/test split
   3. Verify data preprocessing matches training pipeline
   4. Review notebooks/train.ipynb for correct hyperparameters

Q: Data drift report shows significant drift
A: This is monitored via src/drift.py using Evidently AI:
   1. Run: python src/drift.py
   2. Open data_drift_report.html
   3. Significant drift means retraining may be needed
   4. Check if new data distribution differs from training data


================================================================================
7. API ISSUES
================================================================================

Q: API returns "Model not loaded. Service unavailable" (503 error)
A: The model failed to load at startup. Check:
   1. Model files exist in models/ directory
   2. Check API logs for specific error:
      # Local development
      python src/api.py

      # Docker
      docker logs taste-karachi-api

   3. Verify model path is correct in src/api.py:
      MODEL_PATH = Path(__file__).parent.parent / "models"

Q: FastAPI returns 422 Unprocessable Entity
A: Input validation failed. Ensure your request matches the schema:

   {
     "area": "Clifton",  # String
     "price_level": "PRICE_LEVEL_MODERATE",  # String (specific values)
     "category": "Pakistani",  # String
     "latitude": 24.8138,  # Float (-90 to 90)
     "longitude": 67.0011,  # Float (-180 to 180)
     "dine_in": true,  # Boolean (all 23 amenity fields required)
     ... (23 binary fields)
   }

   Use /docs endpoint to see full schema and test interactively.

Q: Cannot connect to API at localhost:8000
A: Check:
   1. API is running:
      # Check Docker
      docker ps

      # Check local process
      netstat -ano | findstr :8000  (Windows)
      lsof -i :8000  (Mac/Linux)

   2. Correct URL: http://localhost:8000 (not https)

   3. Firewall not blocking port 8000

   4. If using Docker, container is up:
      docker logs taste-karachi-api

Q: CORS errors when calling API from browser
A: FastAPI CORS not configured. Add to src/api.py:

   from fastapi.middleware.cors import CORSMiddleware

   app.add_middleware(
       CORSMiddleware,
       allow_origins=["*"],
       allow_credentials=True,
       allow_methods=["*"],
       allow_headers=["*"],
   )

Q: How do I test the API?
A: Multiple options:
   1. Interactive docs: http://localhost:8000/docs
   2. Test script: python src/test.py
   3. cURL:
      curl -X POST http://localhost:8000/predict \
           -H "Content-Type: application/json" \
           -d @test_payload.json
   4. Streamlit UI: http://localhost:8501

Q: API is slow to respond (>5 seconds)
A: Check:
   1. Model loading happens at startup (should be fast after)
   2. Use health check to verify: curl http://localhost:8000/health
   3. Check system resources (CPU/Memory)
   4. Ensure not rebuilding Docker on every request


================================================================================
8. DEVELOPMENT ENVIRONMENT ISSUES
================================================================================

Q: Jupyter Notebook kernel dies when running train.ipynb
A: This is usually memory issue. Solutions:
   1. Close other applications
   2. Reduce RandomizedSearchCV iterations in train.ipynb
   3. Run in smaller batches (train fewer models at once)
   4. Increase system swap/virtual memory

Q: VSCode doesn't recognize Python modules
A: Solutions:
   1. Select correct Python interpreter:
      - Ctrl+Shift+P (Windows/Linux) or Cmd+Shift+P (Mac)
      - Type: "Python: Select Interpreter"
      - Choose venv/bin/python or venv/Scripts/python.exe

   2. Restart VSCode after selecting interpreter

   3. Install Python extension for VSCode

Q: Pre-commit hooks fail
A: Check .pre-commit-config.yaml configuration:

   # Install pre-commit
   pip install pre-commit

   # Install hooks
   pre-commit install

   # Run manually to see specific errors
   pre-commit run --all-files

   Common issues:
   - Trailing whitespace: Auto-fixed by hook
   - Secret detection: Remove secrets from code
   - End of file: Ensure newline at end of files

Q: Streamlit app won't start
A: Check:
   1. Streamlit installed:
      pip install streamlit==1.28.2

   2. Port 8501 not in use (check with netstat/lsof)

   3. Run with debug:
      streamlit run src/streamlit_app.py --server.port=8501 --logger.level=debug

   4. Check for syntax errors in src/streamlit_app.py

Q: Git shows too many untracked files
A: Check .gitignore is working:

   # Common gitignored items:
   - data/                 # Data files
   - models/               # Model artifacts
   - mlruns/               # MLflow experiments
   - mlartifacts/          # MLflow artifacts
   - __pycache__/          # Python cache
   - .ipynb_checkpoints/   # Jupyter checkpoints
   - venv/                 # Virtual environment

   If .gitignore not working:
   git rm -r --cached .
   git add .
   git commit -m "Fix gitignore"


================================================================================
9. MLFLOW ISSUES
================================================================================

Q: MLflow UI won't start
A: Start MLflow tracking server:

   mlflow ui --port 5000

   Then access: http://localhost:5000

Q: MLflow experiments not showing up
A: Check:
   1. MLflow tracking URI is set:
      import mlflow
      mlflow.set_tracking_uri("http://127.0.0.1:5000")

   2. MLflow server is running

   3. Check mlruns/ directory exists

   4. View from correct directory (project root)

Q: Cannot log model to MLflow
A: Ensure:
   1. Experiment name exists:
      mlflow.set_experiment("Taste Karachi Rating Predictor Experiments")

   2. Model is fitted before logging:
      model.fit(X_train, y_train)
      mlflow.sklearn.log_model(model, "model_name")

   3. MLflow tracking server is running

   4. Sufficient disk space for artifacts

Q: "INVALID_PARAMETER_VALUE: Model name is invalid" error
A: Model registry has strict naming rules:
   - No spaces (use underscores)
   - Alphanumeric characters only
   - No special characters except underscore and hyphen

   Correct: "Restaurant_rating_prediction_regression"
   Wrong: "Restaurant Rating Prediction (Regression)"

Q: Model version conflicts in registry
A: MLflow auto-increments versions. To use specific version:

   # Load specific version
   model = mlflow.pyfunc.load_model(
       model_uri="models:/Restaurant_rating_prediction_regression/1"
   )

   # Or use Production stage
   model = mlflow.pyfunc.load_model(
       model_uri="models:/Restaurant_rating_prediction_regression/Production"
   )


================================================================================
10. TROUBLESHOOTING TIPS
================================================================================

Q: Where can I find logs for debugging?
A: Log locations:
   - FastAPI local: Terminal output where you ran python src/api.py
   - FastAPI Docker: docker logs taste-karachi-api
   - Streamlit Docker: docker logs taste-karachi-frontend
   - MLflow: mlruns/<experiment_id>/meta.yaml
   - Jupyter: .ipynb_checkpoints/

Q: How do I perform a clean reset?
A: Complete project reset:

   # Stop all containers
   docker-compose down -v

   # Remove Docker images
   docker rmi taste-karachi

   # Clean Python cache
   find . -type d -name __pycache__ -exec rm -rf {} +  (Mac/Linux)
   # Windows: manually delete __pycache__ folders

   # Remove virtual environment
   rm -rf venv  (Mac/Linux)
   rmdir /s venv  (Windows)

   # Recreate virtual environment
   python -m venv venv
   source venv/bin/activate  (Mac/Linux)
   .\venv\Scripts\Activate.ps1  (Windows)

   # Reinstall dependencies
   pip install --upgrade pip
   pip install -r requirements.txt

   # Rebuild Docker
   docker-compose build --no-cache
   docker-compose up

Q: How do I verify my installation is correct?
A: Run these verification steps:

   1. Check Python version:
      python --version  # Should be 3.10 or 3.11

   2. Check packages installed:
      pip list
      # Should include: mlflow, fastapi, scikit-learn, streamlit, etc.

   3. Check Docker:
      docker --version
      docker-compose --version

   4. Test model loading:
      python -c "import mlflow; model = mlflow.pyfunc.load_model('./models'); print('Model loaded!')"

   5. Health check:
      curl http://localhost:8000/health

   6. Run test script:
      python src/test.py

Q: Performance optimization tips
A: To improve performance:
   1. Use Docker Compose (faster than individual containers)
   2. Don't rebuild Docker unnecessarily (use docker-compose up without --build)
   3. Load model once at startup (already implemented in src/api.py)
   4. Use model caching in MLflow
   5. Allocate sufficient Docker resources (4GB+ RAM recommended)
   6. Use SSD for Docker storage

Q: How do I update dependencies safely?
A: Best practices:

   1. Check for security updates:
      pip list --outdated

   2. Update in virtual environment first:
      pip install --upgrade <package_name>

   3. Test thoroughly

   4. Update requirements.txt:
      pip freeze > requirements.txt

   5. Test Docker build:
      docker-compose build

   6. Be careful with major version updates (especially scikit-learn, mlflow)

Q: Getting "ImportError: DLL load failed" on Windows
A: Install Visual C++ Redistributable:
   1. Download from: https://aka.ms/vs/17/release/vc_redist.x64.exe
   2. Install and restart
   3. Try importing package again

Q: Mac "SSL: CERTIFICATE_VERIFY_FAILED" error
A: Run Python's certificate installer:

   # For Python 3.10
   /Applications/Python\ 3.10/Install\ Certificates.command

   Or install certifi:
   pip install --upgrade certifi


================================================================================
ADDITIONAL RESOURCES
================================================================================

Documentation:
- FastAPI: https://fastapi.tiangolo.com/
- MLflow: https://mlflow.org/docs/latest/index.html
- Scikit-learn: https://scikit-learn.org/stable/
- Docker: https://docs.docker.com/
- Streamlit: https://docs.streamlit.io/

Project Files:
- README.md: Quick start guide
- CONTRIBUTION.md: Contribution guidelines
- CODE_OF_CONDUCT.md: Code of conduct
- requirements.txt: Python dependencies
- Dockerfile: Container definition
- docker-compose.yml: Multi-container setup

Key Endpoints:
- API: http://localhost:8000
- API Docs: http://localhost:8000/docs
- Health Check: http://localhost:8000/health
- Streamlit UI: http://localhost:8501
- MLflow UI: http://localhost:5000


================================================================================

